{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_10848\\1959731173.py:3: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  with open('Hog RAGger Dataset\\corpus.json', 'r') as file:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Open and read the JSON file\n",
    "with open('Hog RAGger Dataset\\corpus.json', 'r') as file:\n",
    "    corpus_data = json.load(file)  # Parse the JSON data into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_article(article):\n",
    "    # Normalize text (convert to lowercase, remove special characters, etc.)\n",
    "    body = article['body'].lower().strip()\n",
    "    \n",
    "    # Tokenization (could be done using sentence transformers or other tokenizers)\n",
    "    tokens = body.split()\n",
    "\n",
    "    # Split long texts into chunks (e.g., 512 tokens each)\n",
    "    max_length = 512\n",
    "    chunks = [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Process the entire corpus\n",
    "processed_corpus = []\n",
    "for article in corpus_data:\n",
    "    article_chunks = preprocess_article(article)\n",
    "    for chunk in article_chunks:\n",
    "        processed_corpus.append({\n",
    "            \"chunk\": \" \".join(chunk),\n",
    "            \"title\": article['title'],\n",
    "            \"author\": article['author'],\n",
    "            \"source\": article['source'],\n",
    "            \"published_at\": article['published_at'],\n",
    "            \"category\": article['category'],\n",
    "            \"url\": article['url']\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Load the pre-trained sentence transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Create an empty list to store metadata\n",
    "metadata_store = []\n",
    "\n",
    "# Initialize FAISS index\n",
    "embedding_dim = 384  # Depends on the model used\n",
    "faiss_index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "# Iterate over the processed corpus and encode chunks\n",
    "for doc in processed_corpus:\n",
    "    # Encode the text chunk\n",
    "    embedding = model.encode(doc['chunk'])\n",
    "    \n",
    "    # Add the embedding to the FAISS index\n",
    "    faiss_index.add(np.array([embedding]))\n",
    "\n",
    "    # Store corresponding metadata\n",
    "    metadata_store.append({\n",
    "        \"title\": doc['title'],\n",
    "        \"author\": doc['author'],\n",
    "        \"source\": doc['source'],\n",
    "        \"published_at\": doc['published_at'],\n",
    "        \"category\": doc['category'],\n",
    "        \"url\": doc['url'],\n",
    "        \"chunk\": doc['chunk']\n",
    "    })\n",
    "\n",
    "# Save FAISS index to disk for future use\n",
    "faiss.write_index(faiss_index, \"corpus_faiss.index\")\n",
    "\n",
    "# Save metadata store for future retrieval\n",
    "import pickle\n",
    "with open('metadata_store.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata_store, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The jury finally hears from Sam Bankman-Fried\n",
      "Author: Elizabeth Lopatto\n",
      "Source: The Verge\n",
      "Published At: 2023-10-28T00:12:41+00:00\n",
      "Body: it is honestly kind of incredible to watch a man torpedo his own credibility on direct testimony. we’re not even at the cross yet, and the judge has already instructed him to answer the question he’s ...\n",
      "--------------------------------------------------\n",
      "Title: Sam Bankman-Fried was a terrible boyfriend\n",
      "Author: Elizabeth Lopatto\n",
      "Source: The Verge\n",
      "Published At: 2023-10-10T23:50:21+00:00\n",
      "Body: i’ve got some shitty ex-boyfriends, but none of them made me the ceo of their sin-eater hedge fund while refusing to give me equity and bragging about how there was a 5 percent chance they’d become th...\n",
      "--------------------------------------------------\n",
      "Title: Is Sam Bankman-Fried a bad ‘man’ or a good ‘boy’? Lawyers swap opening statements before first witnesses take the stand\n",
      "Author: Ben Weiss\n",
      "Source: Fortune\n",
      "Published At: 2023-10-04T23:32:53+00:00\n",
      "Body: processor, and market maker, or financial entity that acts as a trading partner for customers looking to buy and sell cryptocurrencies. in an analogy he employed throughout his opening statement, he s...\n",
      "--------------------------------------------------\n",
      "Title: Is Sam Bankman-Fried a bad ‘man’ or a good ‘boy’? Lawyers swap opening statements before first witnesses take the stand\n",
      "Author: Ben Weiss\n",
      "Source: Fortune\n",
      "Published At: 2023-10-04T23:32:53+00:00\n",
      "Body: who is sam bankman-fried, the former ceo of crypto exchange ftx? is he a liar and a fraud? or did he act in good faith, and like many a startup founder, fly too close to the sun? that answer ultimatel...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query_text = \"Who is the individual associated with cryptocurrency fraud?\"\n",
    "query_embedding = model.encode(query_text)\n",
    "\n",
    "# Search FAISS for top 4 results\n",
    "D, I = faiss_index.search(np.array([query_embedding]), k=4)\n",
    "\n",
    "# Retrieve metadata for top results\n",
    "for idx in I[0]:\n",
    "    result = metadata_store[idx]\n",
    "    print(f\"Title: {result['title']}\")\n",
    "    print(f\"Author: {result['author']}\")\n",
    "    print(f\"Source: {result['source']}\")\n",
    "    print(f\"Published At: {result['published_at']}\")\n",
    "    print(f\"Body: {result['chunk'][:200]}...\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_evidence(results, query):\n",
    "    # Combine evidence from the top documents\n",
    "    aggregated_evidence = []\n",
    "    \n",
    "    for result in results:\n",
    "        evidence = {\n",
    "            \"title\": result['title'],\n",
    "            \"author\": result['author'],\n",
    "            \"source\": result['source'],\n",
    "            \"published_at\": result['published_at'],\n",
    "            \"url\": result['url'],\n",
    "            \"fact\": result['chunk'][:200]  # Extract part of the text relevant to the query\n",
    "        }\n",
    "        aggregated_evidence.append(evidence)\n",
    "    \n",
    "    return aggregated_evidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load T5 model and tokenizer\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "def generate_answer(evidence_list, query):\n",
    "    # Combine the evidence into a single input text\n",
    "    evidence_text = \" \".join([e['fact'] for e in evidence_list])\n",
    "    input_text = f\"question: {query} context: {evidence_text}\"\n",
    "    \n",
    "    # Tokenize the input\n",
    "    input_ids = t5_tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    \n",
    "    # Generate the answer\n",
    "    output_ids = t5_model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "    answer = t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def format_output(query, answer, evidence_list):\n",
    "    output = {\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"question_type\": \"inference_query\",  # As per the problem definition\n",
    "        \"evidence_list\": evidence_list\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"query\": \"Which individual is implicated in both inflating the value of a Manhattan apartment to a figure not yet achieved in New York City's real estate history, according to 'Fortune', and is also accused of adjusting this apartment's valuation to compensate for a loss in another asset's worth, as reported by 'The Age'?\",\n",
      "    \"answer\": \"trump\",\n",
      "    \"question_type\": \"inference_query\",\n",
      "    \"evidence_list\": [\n",
      "        {\n",
      "            \"title\": \"The $777 million surprise: Donald Trump is getting richer\",\n",
      "            \"author\": \"Tom Maloney\",\n",
      "            \"source\": \"The Age\",\n",
      "            \"published_at\": \"2023-11-07T22:22:05+00:00\",\n",
      "            \"url\": \"https://www.theage.com.au/business/companies/the-777-million-surprise-donald-trump-is-getting-richer-20231108-p5eicf.html?ref=rss&utm_medium=rss&utm_source=rss_business\",\n",
      "            \"fact\": \"million the residential condo tower on manhattan\\u2019s upper east side, formerly the hotel delmonico, isn\\u2019t one of trump\\u2019s best-known buildings, but it\\u2019s been the source of some significant asset inflatio\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Donald Trump defrauded banks with 'fantasy' to build his real estate empire, judge rules in a major repudiation against the former president\",\n",
      "            \"author\": \"Michael R. Sisak, The Associated Press\",\n",
      "            \"source\": \"Fortune\",\n",
      "            \"published_at\": \"2023-09-26T21:11:15+00:00\",\n",
      "            \"url\": \"https://fortune.com/2023/09/26/donald-trump-fraud-banks-insurers-real-estate-judge-new-york/\",\n",
      "            \"fact\": \"lawsuit accused trump and his company of routinely inflating the value of assets like skyscrapers, golf courses and his mar-a-lago estate in florida, padding his bottom line by billions. among the all\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"The $777 million surprise: Donald Trump is getting richer\",\n",
      "            \"author\": \"Tom Maloney\",\n",
      "            \"source\": \"The Age\",\n",
      "            \"published_at\": \"2023-11-07T22:22:05+00:00\",\n",
      "            \"url\": \"https://www.theage.com.au/business/companies/the-777-million-surprise-donald-trump-is-getting-richer-20231108-p5eicf.html?ref=rss&utm_medium=rss&utm_source=rss_business\",\n",
      "            \"fact\": \"thousands of pages of exhibits detailing the performance of his assets made available during the trial have provided a deeper look into his fortune. the former president\\u2019s 2021 statement of financial \"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"The $777 million surprise: Donald Trump is getting richer\",\n",
      "            \"author\": \"Tom Maloney\",\n",
      "            \"source\": \"The Age\",\n",
      "            \"published_at\": \"2023-11-07T22:22:05+00:00\",\n",
      "            \"url\": \"https://www.theage.com.au/business/companies/the-777-million-surprise-donald-trump-is-getting-richer-20231108-p5eicf.html?ref=rss&utm_medium=rss&utm_source=rss_business\",\n",
      "            \"fact\": \"to be changing. it took in about $us41 million in revenue last year, according to trump\\u2019s most recent ethics disclosure, compared with $us21 million in 2019. bloomberg values mar-a-lago at $us240 mill\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Encode the query\n",
    "query_text = \"Which individual is implicated in both inflating the value of a Manhattan apartment to a figure not yet achieved in New York City's real estate history, according to 'Fortune', and is also accused of adjusting this apartment's valuation to compensate for a loss in another asset's worth, as reported by 'The Age'?\"\n",
    "query_embedding = model.encode(query_text)\n",
    "\n",
    "# Step 2: Search FAISS for top 4 results\n",
    "D, I = faiss_index.search(np.array([query_embedding]), k=4)\n",
    "\n",
    "# Step 3: Aggregate evidence from the top-ranked results\n",
    "aggregated_evidence = aggregate_evidence([metadata_store[idx] for idx in I[0]], query_text)\n",
    "\n",
    "# Step 4: Generate the answer using the aggregated evidence\n",
    "answer = generate_answer(aggregated_evidence, query_text)\n",
    "\n",
    "# Step 5: Format the output\n",
    "final_output = format_output(query_text, answer, aggregated_evidence)\n",
    "\n",
    "# Print the final output in the required format\n",
    "import json\n",
    "print(json.dumps(final_output, indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mrm8488/bert-small-finetuned-squadv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mrm8488/bert-small-finetuned-squadv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load train.json dataset\n",
    "with open('Hog RAGger Dataset/train.json', 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "# Load zero-shot classification model for yes/no detection\n",
    "classifier = pipeline(\"text-classification\", model=\"typeform/distilbert-base-uncased-mnli\")\n",
    "\n",
    "class YesNoClassifier:\n",
    "    def __init__(self):\n",
    "        # Initialize a text classification pipeline with a pretrained model\n",
    "        self.classifier = pipeline(\"text-classification\", model=\"mrm8488/bert-small-finetuned-squadv2\")\n",
    "\n",
    "    def is_yes_no_question(self, query):\n",
    "        # Define a set of simple rules to check if the query is a yes/no question\n",
    "        yes_no_keywords = ['is', 'are', 'do', 'does', 'did', 'can', 'will', 'was', 'were', 'has', 'have', 'had', 'shall', 'should', 'could']\n",
    "        return any(query.lower().startswith(keyword) for keyword in yes_no_keywords)\n",
    "\n",
    "class YesNoEvidenceClassifierLLM:\n",
    "    def __init__(self):\n",
    "        # Initialize a binary classification pipeline with a suitable model\n",
    "        self.classifier = pipeline(\"text-classification\", model=\"mrm8488/bert-small-finetuned-squadv2\")\n",
    "\n",
    "    def classify(self, data):\n",
    "        answer = data[\"answer\"].strip().lower()  # Normalize the answer\n",
    "        query = data[\"query\"]\n",
    "        evidence_list = data[\"evidence_list\"]\n",
    "\n",
    "        # Concatenate the query and evidence facts into a single context\n",
    "        evidence_texts = \" \".join([evidence[\"fact\"] for evidence in evidence_list])\n",
    "        full_context = f\"Question: {query} Evidence: {evidence_texts} Answer: {answer}\"\n",
    "\n",
    "        # Run classification\n",
    "        result = self.classifier(full_context)\n",
    "\n",
    "        # Interpret the result based on predicted label\n",
    "        label = result[0]['label']\n",
    "        score = result[0]['score']\n",
    "\n",
    "        # Determine if the model agrees with the expected answer\n",
    "        if label == 'positive' and answer == 'yes':\n",
    "            return \"YES\"\n",
    "        elif label == 'negative' and answer == 'no':\n",
    "            return \"NO\"\n",
    "        else:\n",
    "            return \"Insufficient Information\"\n",
    "\n",
    "yesNO = YesNoEvidenceClassifierLLM()\n",
    "classifier = YesNoClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counters for accuracy\n",
    "correct_predictions = 0\n",
    "total_queries = len(train_data)\n",
    "\n",
    "# Loop through each query in the dataset\n",
    "for item in train_data:\n",
    "    query = item['query']\n",
    "    true_answer = item['answer']\n",
    "    # Encode the query, search FAISS, and aggregate evidence\n",
    "    query_embedding = model.encode(query)\n",
    "    D, I = faiss_index.search(np.array([query_embedding]), k=5)\n",
    "    top_docs = [metadata_store[idx] for idx in I[0]]\n",
    "    aggregated_evidence = aggregate_evidence(top_docs, query)\n",
    "    # Step 1: Check if the query is a yes/no question\n",
    "    if classifier.is_yes_no_question(query):\n",
    "        # print(\"Y/N\",end=\",  \")\n",
    "        # Generate the answer and calculate confidence\n",
    "        answer = generate_answer(aggregated_evidence, query)\n",
    "        final= format_output(query, answer, aggregated_evidence)\n",
    "        final_answer = yesNO.classify(final)\n",
    "\n",
    "    else:\n",
    "        # print(\"Sub\",end=\",  \")\n",
    "        # If not a yes/no question, use your original pipeline\n",
    "        final_answer = generate_answer(aggregated_evidence, query).strip().lower()\n",
    "\n",
    "    # Step 4: Check if the generated answer matches the true answer\n",
    "    if final_answer == true_answer.strip().lower():\n",
    "        correct_predictions += 1\n",
    "    \n",
    "    # Print results for inspection\n",
    "    # print(f\"Actual: {true_answer}, Predicted: {final_answer}\")\n",
    "    print(f\"Actual: {true_answer}, Predicted: {final_answer}\")\n",
    "    # if((true_answer==\"Yes\" or true_answer==\"No\")):\n",
    "    #     print(f\"Query: {query}\")\n",
    "    #     print(f\"Actual: {true_answer}, Predicted: {final_answer}\")\n",
    "\n",
    "# Step 5: Calculate accuracy\n",
    "accuracy = correct_predictions / total_queries * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
